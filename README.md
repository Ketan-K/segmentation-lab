# Segmentation Lab

A WebRTC-based video conferencing application that serves as a testing laboratory for multiple AI-powered virtual background segmentation technologies. Compare and evaluate SAM2 (Segment Anything Model 2), BodyPix, MediaPipe, and WebGL models in real-time.

## Live Demo

Try the application online: [https://segmentation-lab.onrender.com/](https://segmentation-lab.onrender.com/)

## Features

- ğŸ§ª Test and compare multiple AI segmentation models in real-time
- ğŸ“Š Detailed performance metrics for each model
- ğŸ”„ Easy switching between models during a call
- ğŸ¥ Real-time video conferencing using WebRTC
- ğŸ”— Easy meeting creation and joining with shareable meeting codes
- ğŸ–¼ï¸ Multiple background options with support for:
  - MediaPipe Selfie Segmentation (currently available)
  - SAM2 (Segment Anything Model 2) - coming soon
  - TensorFlow BodyPix - coming soon
  - WebGL-based segmentation - coming soon
- ğŸï¸ Built-in background images (beach, office) and custom background upload
- ğŸ›ï¸ Audio/video controls

## Getting Started

### Prerequisites

- Node.js (16+)
- Modern web browser with WebRTC support (Chrome, Firefox, Edge, Safari)

### Installation

1. Clone the repository:
   ```
   git clone https://github.com/Ketan-K/segmentation-lab.git
   cd segmentation-lab
   ```

2. Install dependencies:
   ```
   npm install
   ```

3. Start the server:
   ```
   npm start
   ```

4. Open your browser and navigate to:
   ```
   http://localhost:3000
   ```

### Development

This project includes a `.gitignore` file that excludes:
- Node.js dependencies (`node_modules`)
- Environment files (`.env`, etc.)
- Build artifacts
- Log files
- Editor-specific files
- Cache files

For development:
1. Fork or clone the repository
2. Run `npm install` to install dependencies
3. Make your changes
4. Test locally with `npm start`
5. Submit a pull request with your improvements

## Usage

### Starting a Meeting

1. Click "Create Meeting" on the home page
2. Grant camera and microphone permissions when prompted
3. Share the generated meeting code with others

### Joining a Meeting

1. Enter the meeting code in the "Join Meeting" input field
2. Click "Join Meeting"
3. Grant camera and microphone permissions when prompted

### Using Virtual Backgrounds

1. During a call, click "Virtual Background" button
2. Select a segmentation model from the dropdown (MediaPipe is recommended for most devices)
3. Choose a background type:
   - None (original background)
   - Blur (blurred background)
   - Beach
   - Office
   - Custom (upload your own image)

## Segmentation Models

### MediaPipe Model
- Uses Google's MediaPipe Selfie Segmentation
- Good balance of performance and quality
- Works well on most devices
- **Currently the only implemented model**

### SAM2 Model (Coming Soon)
- Based on Meta's Segment Anything Model 2
- Highest quality segmentation
- More resource-intensive

### BodyPix Model (Coming Soon)
- TensorFlow.js-based segmentation
- Reasonable quality
- Higher resource usage

### WebGL Model (Coming Soon)
- Custom WebGL-based segmentation
- Fastest performance
- Lower quality than other models

## Performance Metrics

The application provides real-time performance metrics for each segmentation model:
- FPS (Frames Per Second)
- Segmentation Time (ms)
- Frame Processing Time (ms)

This allows you to compare the efficiency of different models on your device.

## Project Structure

```
segmentation-lab/
â”œâ”€â”€ app.js             # Main client-side application logic
â”œâ”€â”€ index.html         # Main HTML file
â”œâ”€â”€ package.json       # Project dependencies
â”œâ”€â”€ server.js          # WebRTC signaling server
â”œâ”€â”€ styles.css         # Application styles
â”œâ”€â”€ .gitignore         # Git ignore patterns
â”œâ”€â”€ assets/            # Background images
â”‚   â”œâ”€â”€ beach.png
â”‚   â””â”€â”€ office.png
â”œâ”€â”€ js/                # JavaScript modules
â”‚   â”œâ”€â”€ components/    # UI components
â”‚   â”‚   â”œâ”€â”€ eventHandlers.js     # Event handling logic
â”‚   â”‚   â”œâ”€â”€ performanceMetrics.js # Performance measuring utilities
â”‚   â”‚   â””â”€â”€ uiController.js      # UI manipulation functions
â”‚   â”œâ”€â”€ services/      # Services
â”‚   â”‚   â”œâ”€â”€ backgroundService.js # Background effects processing
â”‚   â”‚   â”œâ”€â”€ socketService.js     # Socket.io communication
â”‚   â”‚   â””â”€â”€ webrtcService.js     # WebRTC connection management
â”‚   â””â”€â”€ utils/         # Utility functions
â”‚       â”œâ”€â”€ alertUtils.js        # Alert/notification utilities
â”‚       â””â”€â”€ generalUtils.js      # General helper functions
â””â”€â”€ models/            # Segmentation model implementations
    â”œâ”€â”€ BaseBackgroundModel.js   # Base model class
    â””â”€â”€ MediaPipeModel.js        # MediaPipe integration
```

## Connect

- [GitHub Repository](https://github.com/Ketan-K/segmentation-lab)
- [LinkedIn](https://in.linkedin.com/in/ketan-k)

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- [WebRTC](https://webrtc.org/)
- [Socket.io](https://socket.io/)
- [TensorFlow.js](https://www.tensorflow.org/js)
- [MediaPipe](https://mediapipe.dev/)
- [Segment Anything Model 2](https://segment-anything.com/)